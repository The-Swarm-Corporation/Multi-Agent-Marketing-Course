{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fadfc2e",
   "metadata": {},
   "source": [
    "\n",
    "# Module 4: AI-Powered Marketing Personalization & Prediction\n",
    "\n",
    "## Learning Objectives\n",
    "- Build type-safe personalization systems\n",
    "- Implement predictive analytics with error tracking\n",
    "- Create robust customer segmentation\n",
    "- Develop production-ready A/B testing\n",
    "- Design conversion prediction models\n",
    "\n",
    "## Prerequisites\n",
    "- Modules 1-3 completion\n",
    "- Python type hinting knowledge\n",
    "- Basic error handling understanding\n",
    "- API access for your platforms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149f50b9",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Environment Setup\n",
    "\n",
    "Install required packages and configure logging.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f540a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install swarms python-dotenv pandas numpy scikit-learn loguru\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f346cce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from typing import Dict, List, Optional, Any, Tuple, Union\n",
    "from datetime import datetime, timedelta\n",
    "from loguru import logger\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from dataclasses import dataclass\n",
    "from dotenv import load_dotenv\n",
    "from swarms import Agent, MixtureOfAgents\n",
    "from swarm_models import OpenAIChat\n",
    "\n",
    "# Configure logger\n",
    "logger.add(\"marketing_ai.log\", rotation=\"500 MB\")\n",
    "\n",
    "# Load environment\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize model\n",
    "model = OpenAIChat(\n",
    "    openai_api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    model_name=\"gpt-4\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "@dataclass\n",
    "class MarketingMetrics:\n",
    "    conversion_rate: float\n",
    "    engagement_rate: float\n",
    "    roi: float\n",
    "    timestamp: datetime\n",
    "\n",
    "@dataclass\n",
    "class UserSegment:\n",
    "    segment_id: int\n",
    "    behavior_score: float\n",
    "    value_score: float\n",
    "    engagement_level: str\n",
    "    characteristics: Dict[str, Any]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c7123e",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Type-Safe Content Personalization System\n",
    "\n",
    "Create a robust personalization system with proper error handling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286fc3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ContentPersonalizer:\n",
    "    def __init__(self, model: Any) -> None:\n",
    "        self.model = model\n",
    "        self.agent = Agent(\n",
    "            agent_name=\"Personalization-Expert\",\n",
    "            system_prompt=\"\"\"\n",
    "            You are an AI Marketing Personalization Expert. Create personalized content \n",
    "            based on user segments and behaviors. Return ONLY JSON in this format:\n",
    "            {\n",
    "                \"segment_name\": str,\n",
    "                \"personalized_content\": {\n",
    "                    \"headline\": str,\n",
    "                    \"main_message\": str,\n",
    "                    \"call_to_action\": str,\n",
    "                    \"tone\": str,\n",
    "                    \"key_benefits\": list\n",
    "                },\n",
    "                \"channel_adaptations\": {\n",
    "                    \"email\": {content details},\n",
    "                    \"social\": {content details},\n",
    "                    \"web\": {content details}\n",
    "                },\n",
    "                \"predicted_engagement_score\": float\n",
    "            }\n",
    "            \"\"\",\n",
    "            llm=model,\n",
    "            output_type=\"json\"\n",
    "        )\n",
    "    \n",
    "    def create_user_segment(self, user_data: pd.DataFrame) -> Dict[int, UserSegment]:\n",
    "        try:\n",
    "            scaler = StandardScaler()\n",
    "            features_scaled = scaler.fit_transform(user_data)\n",
    "            \n",
    "            kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "            segments = kmeans.fit_predict(features_scaled)\n",
    "            \n",
    "            user_data['segment'] = segments\n",
    "            segment_profiles = user_data.groupby('segment').mean()\n",
    "            \n",
    "            user_segments: Dict[int, UserSegment] = {}\n",
    "            for segment_id in range(len(segment_profiles)):\n",
    "                profile = segment_profiles.loc[segment_id]\n",
    "                user_segments[segment_id] = UserSegment(\n",
    "                    segment_id=segment_id,\n",
    "                    behavior_score=float(profile['engagement_rate']),\n",
    "                    value_score=float(profile['avg_order_value']),\n",
    "                    engagement_level=self._calculate_engagement_level(profile),\n",
    "                    characteristics=profile.to_dict()\n",
    "                )\n",
    "            \n",
    "            return user_segments\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in create_user_segment: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def _calculate_engagement_level(self, profile: pd.Series) -> str:\n",
    "        engagement_score = float(profile['engagement_rate'])\n",
    "        if engagement_score > 0.7:\n",
    "            return \"high\"\n",
    "        elif engagement_score > 0.3:\n",
    "            return \"medium\"\n",
    "        return \"low\"\n",
    "    \n",
    "    def generate_personalized_content(self, segment: UserSegment) -> Dict[str, Any]:\n",
    "        try:\n",
    "            response = self.agent.run(json.dumps(segment.__dict__))\n",
    "            return json.loads(response)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error generating content for segment {segment.segment_id}: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "# Example usage with type hints\n",
    "def create_sample_data() -> pd.DataFrame:\n",
    "    return pd.DataFrame({\n",
    "        'engagement_rate': np.random.uniform(0, 1, 1000),\n",
    "        'purchase_frequency': np.random.uniform(0, 10, 1000),\n",
    "        'avg_order_value': np.random.uniform(50, 500, 1000),\n",
    "        'email_open_rate': np.random.uniform(0, 1, 1000),\n",
    "        'website_visits': np.random.uniform(1, 100, 1000)\n",
    "    })\n",
    "\n",
    "# Initialize and run\n",
    "personalizer = ContentPersonalizer(model)\n",
    "sample_data = create_sample_data()\n",
    "\n",
    "try:\n",
    "    segments = personalizer.create_user_segment(sample_data)\n",
    "    content = personalizer.generate_personalized_content(\n",
    "        next(iter(segments.values()))\n",
    "    )\n",
    "    print(json.dumps(content, indent=2))\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error in personalization workflow: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9593fd",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Type-Safe Predictive Analytics\n",
    "\n",
    "Build a robust prediction system with proper error handling and type safety.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a06fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dataclass\n",
    "class CampaignPrediction:\n",
    "    conversion_rate: float\n",
    "    engagement_rate: float\n",
    "    roi: float\n",
    "    confidence_score: float\n",
    "    contributing_factors: List[Dict[str, Any]]\n",
    "\n",
    "class PredictiveAnalytics:\n",
    "    def __init__(self, model: Any) -> None:\n",
    "        self.model = model\n",
    "        self.prediction_agent = Agent(\n",
    "            agent_name=\"Prediction-Expert\",\n",
    "            system_prompt=\"\"\"\n",
    "            You are an AI Marketing Prediction Expert. Analyze marketing data and \n",
    "            predict outcomes. Return ONLY JSON in this format:\n",
    "            {\n",
    "                \"predictions\": {\n",
    "                    \"conversion_rate\": float,\n",
    "                    \"engagement_rate\": float,\n",
    "                    \"roi\": float,\n",
    "                    \"confidence_score\": float\n",
    "                },\n",
    "                \"contributing_factors\": [\n",
    "                    {\n",
    "                        \"factor\": str,\n",
    "                        \"impact_score\": float,\n",
    "                        \"recommendation\": str\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "            \"\"\",\n",
    "            llm=model,\n",
    "            output_type=\"json\"\n",
    "        )\n",
    "    \n",
    "    def analyze_historical_data(\n",
    "        self, \n",
    "        data: pd.DataFrame\n",
    "    ) -> Dict[str, MarketingMetrics]:\n",
    "        try:\n",
    "            metrics_by_month: Dict[str, MarketingMetrics] = {}\n",
    "            \n",
    "            for month, group in data.groupby(data.index.to_period('M')):\n",
    "                metrics_by_month[str(month)] = MarketingMetrics(\n",
    "                    conversion_rate=float(group['conversion_rate'].mean()),\n",
    "                    engagement_rate=float(group['engagement_rate'].mean()),\n",
    "                    roi=float(group['roi'].mean()),\n",
    "                    timestamp=group.index[0].to_pydatetime()\n",
    "                )\n",
    "            \n",
    "            return metrics_by_month\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error analyzing historical data: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def predict_campaign_performance(\n",
    "        self,\n",
    "        historical_metrics: Dict[str, MarketingMetrics],\n",
    "        campaign_data: Dict[str, Any]\n",
    "    ) -> CampaignPrediction:\n",
    "        try:\n",
    "            analysis_data = {\n",
    "                'historical_metrics': {\n",
    "                    k: v.__dict__ for k, v in historical_metrics.items()\n",
    "                },\n",
    "                'campaign_details': campaign_data\n",
    "            }\n",
    "            \n",
    "            prediction = json.loads(\n",
    "                self.prediction_agent.run(json.dumps(analysis_data))\n",
    "            )\n",
    "            \n",
    "            return CampaignPrediction(\n",
    "                conversion_rate=prediction['predictions']['conversion_rate'],\n",
    "                engagement_rate=prediction['predictions']['engagement_rate'],\n",
    "                roi=prediction['predictions']['roi'],\n",
    "                confidence_score=prediction['predictions']['confidence_score'],\n",
    "                contributing_factors=prediction['contributing_factors']\n",
    "            )\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error predicting campaign performance: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "# Example usage\n",
    "def create_historical_data() -> pd.DataFrame:\n",
    "    dates = pd.date_range(start='2023-01-01', end='2024-01-01', freq='D')\n",
    "    return pd.DataFrame({\n",
    "        'conversion_rate': np.random.normal(0.15, 0.03, len(dates)),\n",
    "        'engagement_rate': np.random.normal(0.25, 0.05, len(dates)),\n",
    "        'roi': np.random.normal(2.5, 0.5, len(dates))\n",
    "    }, index=dates)\n",
    "\n",
    "predictor = PredictiveAnalytics(model)\n",
    "historical_data = create_historical_data()\n",
    "\n",
    "try:\n",
    "    historical_metrics = predictor.analyze_historical_data(historical_data)\n",
    "    \n",
    "    campaign_data = {\n",
    "        \"type\": \"product_launch\",\n",
    "        \"budget\": 50000,\n",
    "        \"duration_days\": 30,\n",
    "        \"channels\": [\"email\", \"social\", \"ppc\"],\n",
    "        \"target_audience\": \"tech_professionals\"\n",
    "    }\n",
    "    \n",
    "    prediction = predictor.predict_campaign_performance(\n",
    "        historical_metrics,\n",
    "        campaign_data\n",
    "    )\n",
    "    \n",
    "    print(f\"Campaign Prediction:\")\n",
    "    print(f\"Conversion Rate: {prediction.conversion_rate:.2%}\")\n",
    "    print(f\"ROI: {prediction.roi:.2f}x\")\n",
    "    print(\"Contributing Factors:\")\n",
    "    for factor in prediction.contributing_factors:\n",
    "        print(f\"- {factor['factor']}: Impact {factor['impact_score']:.2f}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    logger.error(f\"Error in prediction workflow: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4538bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _generate_recommendations(\n",
    "        self,\n",
    "        platform_metrics: Dict[str, PlatformMetrics]\n",
    "    ) -> List[str]:\n",
    "        recommendations = []\n",
    "        \n",
    "        for platform, metrics in platform_metrics.items():\n",
    "            # Check engagement rates\n",
    "            if metrics.engagement_rate < 0.05:\n",
    "                recommendations.append(\n",
    "                    f\"Increase {platform} engagement by optimizing posting times and content format\"\n",
    "                )\n",
    "            \n",
    "            # Check reach metrics\n",
    "            if metrics.reach < 1000:  # Customize threshold based on goals\n",
    "                recommendations.append(\n",
    "                    f\"Expand {platform} reach through targeted promotion and hashtag optimization\"\n",
    "                )\n",
    "            \n",
    "            # Platform-specific recommendations\n",
    "            if platform == \"linkedin\":\n",
    "                if metrics.raw_metrics.get('share_count', 0) < 10:\n",
    "                    recommendations.append(\n",
    "                        \"Enhance LinkedIn shareability by including industry insights and statistics\"\n",
    "                    )\n",
    "                    \n",
    "            elif platform == \"instagram\":\n",
    "                if metrics.raw_metrics.get('saves', 0) < 50:\n",
    "                    recommendations.append(\n",
    "                        \"Improve Instagram save rate by creating more valuable, saveable content\"\n",
    "                    )\n",
    "                    \n",
    "            elif platform == \"youtube\":\n",
    "                if float(metrics.raw_metrics.get('averageViewDuration', 0)) < 60:\n",
    "                    recommendations.append(\n",
    "                        \"Increase YouTube watch time by optimizing first 30 seconds of videos\"\n",
    "                    )\n",
    "        \n",
    "        return recommendations\n",
    "\n",
    "# Example usage of analytics\n",
    "analytics = CrossPlatformAnalytics(platform_manager)\n",
    "\n",
    "# Sample content IDs from previous publications\n",
    "content_ids = {\n",
    "    'linkedin': 'your_linkedin_post_id',\n",
    "    'instagram': 'your_instagram_post_id',\n",
    "    'youtube': 'your_youtube_video_id'\n",
    "}\n",
    "\n",
    "try:\n",
    "    report = analytics.generate_report(\n",
    "        start_date=datetime.now() - timedelta(days=7),\n",
    "        end_date=datetime.now(),\n",
    "        content_ids=content_ids\n",
    "    )\n",
    "    \n",
    "    print(\"Analytics Report:\")\n",
    "    print(f\"Total Reach: {report.total_reach:,}\")\n",
    "    print(f\"Total Engagement: {report.total_engagement:,}\")\n",
    "    print(\"Top Performing Content:\")\n",
    "    for content in report.top_performing_content:\n",
    "        print(f\"- {content['platform']}: {content['engagement_rate']:.2%} engagement\")\n",
    "    print(\"Recommendations:\")\n",
    "    for rec in report.recommendations:\n",
    "        print(f\"- {rec}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    logger.error(f\"Analytics reporting error: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb1d1b1",
   "metadata": {},
   "source": [
    "\n",
    "## Automated Content Optimization System\n",
    "\n",
    "Create a system that automatically optimizes content based on performance data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd518c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dataclass\n",
    "class OptimizationSuggestion:\n",
    "    platform: str\n",
    "    content_type: str\n",
    "    changes: List[str]\n",
    "    expected_impact: float\n",
    "    implementation_priority: str\n",
    "\n",
    "class ContentOptimizer:\n",
    "    def __init__(self, platform_manager: PlatformManager) -> None:\n",
    "        self.platform_manager = platform_manager\n",
    "        self.optimization_agent = Agent(\n",
    "            agent_name=\"Content-Optimization-Expert\",\n",
    "            system_prompt=\"\"\"\n",
    "            You are a Content Optimization Expert. Analyze performance data and suggest\n",
    "            improvements. Return ONLY JSON in this format:\n",
    "            {\n",
    "                \"optimizations\": {\n",
    "                    \"platform\": str,\n",
    "                    \"content_changes\": list,\n",
    "                    \"timing_changes\": list,\n",
    "                    \"format_changes\": list,\n",
    "                    \"impact_score\": float,\n",
    "                    \"priority\": str\n",
    "                },\n",
    "                \"a_b_test_suggestions\": [\n",
    "                    {\n",
    "                        \"element\": str,\n",
    "                        \"variations\": list,\n",
    "                        \"hypothesis\": str\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "            \"\"\",\n",
    "            llm=platform_manager.model,\n",
    "            output_type=\"json\"\n",
    "        )\n",
    "    \n",
    "    def generate_optimization_plan(\n",
    "        self,\n",
    "        performance_data: AnalyticsReport\n",
    "    ) -> List[OptimizationSuggestion]:\n",
    "        try:\n",
    "            # Prepare performance data for the agent\n",
    "            analysis_data = {\n",
    "                \"metrics\": {\n",
    "                    platform: {\n",
    "                        \"engagement_rate\": metrics.engagement_rate,\n",
    "                        \"reach\": metrics.reach,\n",
    "                        \"interactions\": metrics.interactions,\n",
    "                        \"raw_metrics\": metrics.raw_metrics\n",
    "                    }\n",
    "                    for platform, metrics in performance_data.platform_metrics.items()\n",
    "                },\n",
    "                \"total_performance\": {\n",
    "                    \"reach\": performance_data.total_reach,\n",
    "                    \"engagement\": performance_data.total_engagement\n",
    "                },\n",
    "                \"time_period\": {\n",
    "                    \"start\": performance_data.period_start.isoformat(),\n",
    "                    \"end\": performance_data.period_end.isoformat()\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            # Get optimization suggestions\n",
    "            optimization_response = json.loads(\n",
    "                self.optimization_agent.run(json.dumps(analysis_data))\n",
    "            )\n",
    "            \n",
    "            # Convert to structured suggestions\n",
    "            suggestions = []\n",
    "            for platform, opts in optimization_response[\"optimizations\"].items():\n",
    "                suggestions.append(\n",
    "                    OptimizationSuggestion(\n",
    "                        platform=platform,\n",
    "                        content_type=opts.get(\"content_type\", \"general\"),\n",
    "                        changes=opts[\"content_changes\"] + opts[\"format_changes\"],\n",
    "                        expected_impact=float(opts[\"impact_score\"]),\n",
    "                        implementation_priority=opts[\"priority\"]\n",
    "                    )\n",
    "                )\n",
    "            \n",
    "            return sorted(\n",
    "                suggestions,\n",
    "                key=lambda x: x.expected_impact,\n",
    "                reverse=True\n",
    "            )\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Optimization plan generation error: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    async def apply_optimizations(\n",
    "        self,\n",
    "        suggestions: List[OptimizationSuggestion],\n",
    "        content_pieces: Dict[str, ContentPiece]\n",
    "    ) -> Dict[str, ContentPiece]:\n",
    "        try:\n",
    "            optimized_content = content_pieces.copy()\n",
    "            \n",
    "            for suggestion in suggestions:\n",
    "                if suggestion.platform in optimized_content:\n",
    "                    content = optimized_content[suggestion.platform]\n",
    "                    \n",
    "                    # Apply suggested changes\n",
    "                    for change in suggestion.changes:\n",
    "                        if \"hashtag\" in change.lower():\n",
    "                            # Update hashtags\n",
    "                            new_hashtags = await self._optimize_hashtags(\n",
    "                                content.hashtags,\n",
    "                                suggestion.platform\n",
    "                            )\n",
    "                            content.hashtags = new_hashtags\n",
    "                            \n",
    "                        elif \"timing\" in change.lower():\n",
    "                            # Update posting time\n",
    "                            new_time = await self._optimize_posting_time(\n",
    "                                content.best_posting_time,\n",
    "                                suggestion.platform\n",
    "                            )\n",
    "                            content.best_posting_time = new_time\n",
    "                            \n",
    "                        elif \"format\" in change.lower():\n",
    "                            # Update content format\n",
    "                            new_format = await self._optimize_format(\n",
    "                                content.content_type,\n",
    "                                suggestion.platform\n",
    "                            )\n",
    "                            content.content_type = new_format\n",
    "                    \n",
    "                    optimized_content[suggestion.platform] = content\n",
    "            \n",
    "            return optimized_content\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Optimization application error: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    async def _optimize_hashtags(\n",
    "        self,\n",
    "        current_hashtags: List[str],\n",
    "        platform: str\n",
    "    ) -> List[str]:\n",
    "        try:\n",
    "            # Get trending hashtags for platform\n",
    "            if platform == \"instagram\":\n",
    "                trending = await self._get_instagram_trending_hashtags()\n",
    "            elif platform == \"linkedin\":\n",
    "                trending = await self._get_linkedin_trending_topics()\n",
    "            else:\n",
    "                trending = []\n",
    "            \n",
    "            # Combine current and trending hashtags\n",
    "            all_hashtags = set(current_hashtags + trending)\n",
    "            \n",
    "            # Select top performing hashtags\n",
    "            return list(all_hashtags)[:30]  # Instagram limit\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Hashtag optimization error: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    async def _optimize_posting_time(\n",
    "        self,\n",
    "        current_time: str,\n",
    "        platform: str\n",
    "    ) -> str:\n",
    "        try:\n",
    "            # Get platform-specific engagement data\n",
    "            if platform == \"linkedin\":\n",
    "                response = self.platform_manager.linkedin_api.get_analytics(\n",
    "                    time_range=\"last_30_days\",\n",
    "                    metrics=[\"engagement_by_time\"]\n",
    "                )\n",
    "                best_time = self._analyze_engagement_times(response)\n",
    "                \n",
    "            elif platform == \"instagram\":\n",
    "                insights = self.platform_manager.instagram_account.get_insights(\n",
    "                    params={\n",
    "                        'metric': ['engagement_by_time'],\n",
    "                        'period': 'day'\n",
    "                    }\n",
    "                )\n",
    "                best_time = self._analyze_engagement_times(insights)\n",
    "                \n",
    "            else:\n",
    "                best_time = current_time\n",
    "            \n",
    "            return best_time\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Posting time optimization error: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    async def _optimize_format(\n",
    "        self,\n",
    "        current_format: str,\n",
    "        platform: str\n",
    "    ) -> str:\n",
    "        try:\n",
    "            # Get best performing content formats\n",
    "            if platform == \"instagram\":\n",
    "                insights = self.platform_manager.instagram_account.get_insights(\n",
    "                    params={\n",
    "                        'metric': ['engagement_by_format'],\n",
    "                        'period': 'lifetime'\n",
    "                    }\n",
    "                )\n",
    "                best_format = self._analyze_format_performance(insights)\n",
    "                \n",
    "            elif platform == \"linkedin\":\n",
    "                analytics = self.platform_manager.linkedin_api.get_analytics(\n",
    "                    metrics=[\"engagement_by_format\"]\n",
    "                )\n",
    "                best_format = self._analyze_format_performance(analytics)\n",
    "                \n",
    "            else:\n",
    "                best_format = current_format\n",
    "            \n",
    "            return best_format\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Format optimization error: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def _analyze_engagement_times(self, data: Dict[str, Any]) -> str:\n",
    "        # Implement engagement time analysis logic\n",
    "        pass\n",
    "    \n",
    "    def _analyze_format_performance(self, data: Dict[str, Any]) -> str:\n",
    "        # Implement format performance analysis logic\n",
    "        pass\n",
    "\n",
    "# Example usage\n",
    "optimizer = ContentOptimizer(platform_manager)\n",
    "\n",
    "try:\n",
    "    # Get optimization suggestions\n",
    "    suggestions = optimizer.generate_optimization_plan(report)\n",
    "    \n",
    "    print(\"Optimization Suggestions:\")\n",
    "    for suggestion in suggestions:\n",
    "        print(f\"Platform: {suggestion.platform}\")\n",
    "        print(f\"Priority: {suggestion.implementation_priority}\")\n",
    "        print(\"Changes:\")\n",
    "        for change in suggestion.changes:\n",
    "            print(f\"- {change}\")\n",
    "        print(f\"Expected Impact: {suggestion.expected_impact:.2%}\")\n",
    "    \n",
    "    # Apply optimizations\n",
    "    optimized_content = await optimizer.apply_optimizations(\n",
    "        suggestions,\n",
    "        content_pieces\n",
    "    )\n",
    "    \n",
    "    print(\"Optimized Content:\")\n",
    "    for platform, content in optimized_content.items():\n",
    "        print(f\"{platform} Content:\")\n",
    "        print(f\"Type: {content.content_type}\")\n",
    "        print(f\"Best Time: {content.best_posting_time}\")\n",
    "        print(f\"Hashtags: {', '.join(content.hashtags)}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    logger.error(f\"Optimization workflow error: {str(e)}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
